{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparation\n",
    "This script starts with the filtered data and ends with the aggregated group features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "feature_data = pd.read_excel('unprepared_data.xlsx', sheet_name='Sheet1')\n",
    "label_data = pd.read_excel('Clean_Keys.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge features abd labels\n",
    "merged_data = feature_data.merge(\n",
    "    label_data,\n",
    "    how='left',\n",
    "    left_on='Sender',\n",
    "    right_on='Anonymized Name'\n",
    ")\n",
    "merged_data = merged_data.dropna(subset=[\"Trabajo Final\"])\n",
    "merged_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_dummies = pd.get_dummies(merged_data[\"Message Group DTA\"], prefix=\"DTA\")\n",
    "merged_data = pd.concat([merged_data, dta_dummies], axis=1)\n",
    "\n",
    "# Grouping and Aggregating\n",
    "aggregated_data = merged_data.groupby([\"Team\", \"Trabajo Final\"]).agg({\n",
    "    # Numeric Features\n",
    "    \"Sentiment Stars\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                        lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                        lambda x: x.skew(), \n",
    "                        lambda x: x.kurtosis(), \n",
    "                        lambda x: x.max() - x.min()],\n",
    "    \n",
    "    \"Berger Score\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                     lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                     lambda x: x.skew(), \n",
    "                     lambda x: x.kurtosis(), \n",
    "                     lambda x: x.max() - x.min()],\n",
    "    \n",
    "    \"Semantic Similarity\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                            lambda x: np.nanpercentile(x, 75) - np.nanpercentile(x, 25), \n",
    "                            lambda x: x.skew(), \n",
    "                            lambda x: x.dropna().kurtosis() if not x.dropna().empty else 0, \n",
    "                            lambda x: x.max() - x.min()],\n",
    "    \n",
    "    \"Word_Count\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                   lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                   lambda x: x.skew(), \n",
    "                   lambda x: x.kurtosis(), \n",
    "                   lambda x: x.max() - x.min()],\n",
    "\n",
    "    \"Gini_Coefficient_Team\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                   lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                   lambda x: x.skew(), \n",
    "                   lambda x: x.kurtosis(), \n",
    "                   lambda x: x.max() - x.min()],\n",
    "\n",
    "    \"Openness\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                   lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                   lambda x: x.skew(), \n",
    "                   lambda x: x.kurtosis(), \n",
    "                   lambda x: x.max() - x.min()],\n",
    "\n",
    "    \"Conscientiousness\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                   lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                   lambda x: x.skew(), \n",
    "                   lambda x: x.kurtosis(), \n",
    "                   lambda x: x.max() - x.min()],\n",
    "\n",
    "    \"Extraversion\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                   lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                   lambda x: x.skew(), \n",
    "                   lambda x: x.kurtosis(), \n",
    "                   lambda x: x.max() - x.min()],\n",
    "\n",
    "    \"Agreeableness\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                   lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                   lambda x: x.skew(), \n",
    "                   lambda x: x.kurtosis(), \n",
    "                   lambda x: x.max() - x.min()],\n",
    "\n",
    "    \"Neuroticism\": [\"mean\", \"std\", \"max\", \"min\", \"median\", \n",
    "                   lambda x: np.percentile(x, 75) - np.percentile(x, 25), \n",
    "                   lambda x: x.skew(), \n",
    "                   lambda x: x.kurtosis(), \n",
    "                   lambda x: x.max() - x.min()],\n",
    "\n",
    "    \n",
    "    # Other Binary Aggregations\n",
    "    \"ContainsInappropriateWords\": [\"count\", \"sum\", \"mean\"],\n",
    "    \"IsWeekend\": [\"sum\", \"mean\"],\n",
    "})\n",
    "\n",
    "# Flatten MultiIndex column names\n",
    "aggregated_data.columns = [\"_\".join(col).strip() for col in aggregated_data.columns]\n",
    "\n",
    "# Aggregating DTA categories\n",
    "dta_aggregation = merged_data.groupby([\"Team\", \"Trabajo Final\"])[dta_dummies.columns].agg([\"sum\", \"mean\"])\n",
    "\n",
    "# Flatten column names for DTA aggregation\n",
    "dta_aggregation.columns = [\"_\".join(col).strip() for col in dta_aggregation.columns]\n",
    "\n",
    "# Merge DTA aggregation with the main aggregated data\n",
    "aggregated_data = aggregated_data.merge(dta_aggregation, on=[\"Team\", \"Trabajo Final\"], how=\"left\")\n",
    "\n",
    "aggregated_data.fillna(0, inplace=True)\n",
    "\n",
    "# Reset index\n",
    "aggregated_data = aggregated_data.reset_index()\n",
    "\n",
    "# Custom renaming for lambda-generated columns\n",
    "rename_dict = {\n",
    "    \"Sentiment Stars_<lambda_0>\": \"Sentiment Stars_IQR\",\n",
    "    \"Sentiment Stars_<lambda_1>\": \"Sentiment Stars_skew\",\n",
    "    \"Sentiment Stars_<lambda_2>\": \"Sentiment Stars_kurtosis\",\n",
    "    \"Sentiment Stars_<lambda_3>\": \"Sentiment Stars_range\",\n",
    "    \n",
    "    \"Berger Score_<lambda_0>\": \"Berger Score_IQR\",\n",
    "    \"Berger Score_<lambda_1>\": \"Berger Score_skew\",\n",
    "    \"Berger Score_<lambda_2>\": \"Berger Score_kurtosis\",\n",
    "    \"Berger Score_<lambda_3>\": \"Berger Score_range\",\n",
    "    \n",
    "    \"Semantic Similarity_<lambda_0>\": \"Semantic Similarity_IQR\",\n",
    "    \"Semantic Similarity_<lambda_1>\": \"Semantic Similarity_skew\",\n",
    "    \"Semantic Similarity_<lambda_2>\": \"Semantic Similarity_kurtosis\",\n",
    "    \"Semantic Similarity_<lambda_3>\": \"Semantic Similarity_range\",\n",
    "    \n",
    "    \"Word_Count_<lambda_0>\": \"Word_Count_IQR\",\n",
    "    \"Word_Count_<lambda_1>\": \"Word_Count_skew\",\n",
    "    \"Word_Count_<lambda_2>\": \"Word_Count_kurtosis\",\n",
    "    \"Word_Count_<lambda_3>\": \"Word_Count_range\",\n",
    "\n",
    "    \"Gini_Coefficient_Team_<lambda_0>\": \"Gini_Coefficient_Team_IQR\",\n",
    "    \"Gini_Coefficient_Team_<lambda_1>\": \"Gini_Coefficient_Team_skew\",\n",
    "    \"Gini_Coefficient_Team_<lambda_2>\": \"Gini_Coefficient_Team_kurtosis\",\n",
    "    \"Gini_Coefficient_Team_<lambda_3>\": \"Gini_Coefficient_Team_range\",\n",
    "\n",
    "    \"Openness_<lambda_0>\": \"Openness_IQR\",\n",
    "    \"Openness_<lambda_1>\": \"Openness_skew\",\n",
    "    \"Openness_<lambda_2>\": \"Openness_kurtosis\",\n",
    "    \"Openness_<lambda_3>\": \"Openness_range\",\n",
    "\n",
    "    \"Conscientiousness_<lambda_0>\": \"Conscientiousness_IQR\",\n",
    "    \"Conscientiousness_<lambda_1>\": \"Conscientiousness_skew\",\n",
    "    \"Conscientiousness_<lambda_2>\": \"Conscientiousness_kurtosis\",\n",
    "    \"Conscientiousness_<lambda_3>\": \"Conscientiousness_range\",\n",
    "\n",
    "    \"Extraversion_<lambda_0>\": \"Extraversion_IQR\",\n",
    "    \"Extraversion_<lambda_1>\": \"Extraversion_skew\",\n",
    "    \"Extraversion_<lambda_2>\": \"Extraversion_kurtosis\",\n",
    "    \"Extraversion_<lambda_3>\": \"Extraversion_range\",\n",
    "\n",
    "    \"Agreeableness_<lambda_0>\": \"Agreeableness_IQR\",\n",
    "    \"Agreeableness_<lambda_1>\": \"Agreeableness_skew\",\n",
    "    \"Agreeableness_<lambda_2>\": \"Agreeableness_kurtosis\",\n",
    "    \"Agreeableness_<lambda_3>\": \"Agreeableness_range\",\n",
    "\n",
    "    \"Neuroticism_<lambda_0>\": \"Neuroticism_IQR\",\n",
    "    \"Neuroticism_<lambda_1>\": \"Neuroticism_skew\",\n",
    "    \"Neuroticism_<lambda_2>\": \"Neuroticism_kurtosis\",\n",
    "    \"Neuroticism_<lambda_3>\": \"Neuroticism_range\",\n",
    "\n",
    "    \"ContainsInappropriateWords_count\": \"Message_Count\"\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "aggregated_data.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "file_name = \"aggregated_data.xlsx\"\n",
    "aggregated_data.to_excel(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
